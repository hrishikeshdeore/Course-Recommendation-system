{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Engagement Recommendation System\n",
    "This project implements a recommendation system to personalize educational material suggestions for students based on their engagement data and interests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required pacakges and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating synthetic data \n",
    "\n",
    "## We'll create synthetic datasets for:\n",
    "- *Student Data*\n",
    "- *Material Data*\n",
    "- *Engagement Data*\n",
    "\n",
    "For the data generation, we will be using randomly generated data to simulate a realistic student dataset.\n",
    "We define the number of students and create unique StudentIDs using a formatted string.\n",
    "The students are randomly assigned to various courses, academic years, and interests. Each student can have multiple interests, randomly selected from a predefined list.\n",
    "We simulate student performance by generating scores from a normal distribution with some realistic instinct\n",
    "This synthetic student data will be stored in a pandas DataFrame called students, with columns for StudentID, Course, Year, Interests, and Performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate Synthetic Student Data\n",
    "np.random.seed(42)\n",
    "num_students = 100\n",
    "\n",
    "student_ids = [f\"S{str(i).zfill(3)}\" for i in range(1, num_students + 1)]\n",
    "courses = [\"Computer Science\", \"Mechanical Engineering\", \"Electrical Engineering\", \"Civil Engineering\"]\n",
    "years = [1, 2, 3, 4]\n",
    "interests_list = [\"AI\", \"Blockchain\", \"Environmental Science\", \"Robotics\", \"Data Science\", \"Cybersecurity\", \"Energy\", \"Automation\"]\n",
    "\n",
    "students = pd.DataFrame({\n",
    "    \"StudentID\": student_ids,\n",
    "    \"Course\": np.random.choice(courses, num_students),\n",
    "    \"Year\": np.random.choice(years, num_students),\n",
    "    \"Interests\": [np.random.choice(interests_list, size=np.random.randint(1,4), replace=False).tolist() for _ in range(num_students)],\n",
    "    \"Performance\": np.clip(np.random.normal(65, 20, num_students).astype(int), 0, 100)  # Average quiz scores as noramal distribution with mean 65 and dev 20\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study Material Data\n",
    "In this step, we generate synthetic data for the learning materials that will be recommended to the students:\n",
    "\n",
    "We define the number of materials (num_materials) to be generated and assign unique MaterialIDs in a similar way as student IDs.\n",
    "Each material is associated with a subject, which is randomly chosen from the list of student interests (interests_list). This simulates the different topics the materials cover.\n",
    "\n",
    "The difficulty level of the materials is randomly chosen from predefined levels: \"Easy\", \"Medium\", and \"Hard\".\n",
    "Each material is assigned a Popularity score, which is a random integer between 50 and 100, representing how popular the material is based on user interactions or engagement.\n",
    "\n",
    "The ContentLength of each material is also randomly generated, ranging from 15 to 45 pages, to represent the material's size or time to consume.\n",
    "The synthetic material data is stored in a pandas DataFrame called materials, with columns for MaterialID, Subject, Difficulty, Popularity, and ContentLength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Generate Synthetic Material Data\n",
    "num_materials = 50\n",
    "material_ids = [f\"M{str(i).zfill(3)}\" for i in range(1, num_materials + 1)]\n",
    "subjects = interests_list\n",
    "difficulty_levels = [\"Easy\", \"Medium\", \"Hard\"]\n",
    "materials = pd.DataFrame({\n",
    "    \"MaterialID\": material_ids,\n",
    "    \"Subject\": np.random.choice(subjects, num_materials),\n",
    "    \"Difficulty\": np.random.choice(difficulty_levels, num_materials),\n",
    "    \"Popularity\": np.random.uniform(50, 100, num_materials).astype(int),  \n",
    "    \"ContentLength\": np.random.randint(3, 10, num_materials) * 5  \n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data for student-material engagement\n",
    "We create an empty list engagements to store individual engagement records for each student.\n",
    "For each student in the dataset, a random set of materials (between 5 to 15) is selected from the available material_ids to simulate the materials they have viewed.\n",
    "\n",
    "For each viewed material, we log the following information:\n",
    "\n",
    " StudentID: The ID of the student.\\n\n",
    " MaterialID: The ID of the material that the student viewed.\n",
    " Viewed: A flag indicating that the student has viewed the material (set to 1).\n",
    " Rating: A randomly assigned rating between 1 and 5, representing how much the student liked the material.\n",
    "This engagement data is then stored in a pandas DataFrame called engagements, which captures the interaction between students and materials, forming the foundation for the recommendation system's training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Generate Synthetic Engagement Data\n",
    "engagements = []\n",
    "for student in students[\"StudentID\"]:\n",
    "    viewed_materials = np.random.choice(material_ids, size=np.random.randint(5,15), replace=False)\n",
    "    for material in viewed_materials:\n",
    "        engagements.append({\n",
    "            \"StudentID\": student,\n",
    "            \"MaterialID\": material,\n",
    "            \"Viewed\": 1,\n",
    "            \"Rating\": np.random.randint(1,6)  \n",
    "        })\n",
    "\n",
    "engagements = pd.DataFrame(engagements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  StudentID                  Course  Year                                          Interests  Performance\n",
      "0      S001  Electrical Engineering     3  [Environmental Science, Data Science, Blockchain]           21\n",
      "1      S002       Civil Engineering     2                    [Cybersecurity, Blockchain, AI]          100\n",
      "2      S003        Computer Science     2                         [Energy, AI, Data Science]           29\n",
      "3      S004  Electrical Engineering     4                [Automation, Environmental Science]           94\n",
      "4      S005  Electrical Engineering     2              [Cybersecurity, Data Science, Energy]           46\n",
      "  MaterialID       Subject Difficulty  Popularity  ContentLength\n",
      "0       M001        Energy     Medium          60             40\n",
      "1       M002  Data Science       Easy          85             45\n",
      "2       M003            AI       Easy          74             25\n",
      "3       M004            AI     Medium          87             45\n",
      "4       M005            AI       Easy          55             35\n",
      "   StudentID MaterialID  Viewed  Rating\n",
      "0       S001       M031       1       1\n",
      "1       S001       M005       1       4\n",
      "2       S001       M024       1       2\n",
      "3       S001       M037       1       5\n",
      "4       S001       M009       1       1\n",
      "5       S002       M009       1       1\n",
      "6       S002       M012       1       2\n",
      "7       S002       M036       1       5\n",
      "8       S002       M020       1       4\n",
      "9       S002       M006       1       3\n",
      "10      S002       M013       1       4\n",
      "11      S002       M042       1       2\n",
      "12      S002       M025       1       4\n",
      "13      S002       M045       1       1\n",
      "14      S002       M017       1       2\n",
      "15      S002       M026       1       3\n",
      "16      S002       M011       1       1\n",
      "17      S002       M043       1       2\n",
      "18      S003       M003       1       1\n",
      "19      S003       M035       1       3\n"
     ]
    }
   ],
   "source": [
    "# lets have a look at the data\n",
    "pd.set_option('display.width', 1000)\n",
    "print(students.head())\n",
    "print(materials.head())\n",
    "print(engagements.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "Data Preprocessing\n",
    "As the data was generated synthetically using random or semi-random techniques (e.g., from normal distributions for performance scores), we do not require specific preprocessing steps typically necessary for real-world datasets such as handling missing values, outliers, or scaling numerical features.\n",
    "\n",
    "Instead, the focus of preprocessing here is to:\n",
    "\n",
    "Transform categorical data into a machine-readable format (e.g., one-hot encoding for student interests).\n",
    "Convert difficulty levels into numerical values for easier mathematical operations.\n",
    "Merge various datasets (students, materials, engagements) to create a comprehensive profile that can be used directly for further analysis and building the recommendation system.\n",
    "Thus, we skip traditional preprocessing steps like data cleaning and normalization, as the generated data is already in a consistent, usable format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing \n",
    "we perform essential data preprocessing to prepare the dataset for the recommendation system:\n",
    "### One hot encoding required data\n",
    "We use MultiLabelBinarizer() to transform the list of student interests into a one-hot encoded format.\n",
    "Each column represents an interest, and each row for a student will have a 1 if they have that particular interest, otherwise 0.\n",
    "The resulting encoded interests are added to the students DataFrame, replacing the original 'Interests' column.\n",
    "### Map Difficulty Levels:\n",
    "The difficulty levels of the materials (Easy, Medium, Hard) are mapped to numerical values using a dictionary:\n",
    "Easy → 1\n",
    "Medium → 2\n",
    "Hard → 3\n",
    "This mapping is stored in a new column called DifficultyNum in the materials DataFrame to facilitate mathematical computations in the recommendation logic.\n",
    "### Merge Engagement Data:\n",
    "We merge the engagements DataFrame with the materials DataFrame using the MaterialID column to enrich the engagement data with details about the materials (e.g., difficulty, popularity).\n",
    "We then merge this enriched engagement data with the students DataFrame using the StudentID column, combining both student profiles and their interactions with the materials into a comprehensive student_profiles DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Data Preprocessing\n",
    "\n",
    "# a. One-Hot Encode Interests\n",
    "mlb = MultiLabelBinarizer()\n",
    "interests_encoded = pd.DataFrame(mlb.fit_transform(students['Interests']), columns=mlb.classes_)\n",
    "students = pd.concat([students.drop('Interests', axis=1), interests_encoded], axis=1)\n",
    "\n",
    "# b. Map Difficulty Levels\n",
    "difficulty_mapping = {\"Easy\":1, \"Medium\":2, \"Hard\":3}\n",
    "materials[\"DifficultyNum\"] = materials[\"Difficulty\"].map(difficulty_mapping)\n",
    "\n",
    "# c. Merge Engagement Data\n",
    "student_engagement = engagements.merge(materials, on=\"MaterialID\", how=\"left\")\n",
    "student_profiles = students.merge(student_engagement, on=\"StudentID\", how=\"left\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Recommendation function\n",
    "The recommendation system is designed to suggest the most relevant learning materials to a student based on a combination of their interests, academic performance, and the popularity of the materials. Here’s the approach:\n",
    "\n",
    "Extract the student's profile: For the given student, we fetch their interests and performance from the student dataset.\n",
    "\n",
    "Calculate similarity based on interests: We compute a vector for the student's interests and use it to calculate the cosine similarity between the student's interest profile and the subject of each material. This generates an \"Interest Score\" for each material.\n",
    "\n",
    "Performance compatibility: We assess how well the material's difficulty matches the student's performance level. If a student’s performance is close to the difficulty level of the material, the compatibility score will be higher.\n",
    "\n",
    "Total score calculation:\n",
    "\n",
    "The final score is a weighted combination of the interest similarity score (45%), performance compatibility (35%), and material popularity (20%).\n",
    "This total score determines the ranking of each material for the student.\n",
    "Excluding already viewed materials (optional): Optionally, materials that the student has already viewed could be excluded from recommendations, though this feature is commented out in this version.\n",
    "\n",
    "Top N recommendations: The system sorts the materials based on their total score and returns the top N materials as the recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Recommendation Algorithm\n",
    "\n",
    "def recommend_materials(student_id, top_n=5):\n",
    "    # Get the student's profile\n",
    "    student = students[students[\"StudentID\"] == student_id].iloc[0]\n",
    "    # Calculate similarity based on interests\n",
    "    student_interest_vector = student[mlb.classes_].values.reshape(1, -1)\n",
    "    material_subjects = materials[\"Subject\"].apply(lambda x: [x])\n",
    "    material_subjects_encoded = pd.DataFrame(mlb.transform(material_subjects), columns=mlb.classes_)\n",
    "    # Compute cosine similarity\n",
    "    similarities = cosine_similarity(student_interest_vector, material_subjects_encoded)\n",
    "    materials[\"InterestScore\"] = similarities[0]\n",
    "    # Calculate performance compatibility\n",
    "    materials[\"PerformanceCompatibility\"] = 1 - abs(materials[\"DifficultyNum\"] * 33 - student[\"Performance\"])/100\n",
    "    # Calculate total score\n",
    "    materials[\"TotalScore\"] = (0.45 * materials[\"InterestScore\"] +\n",
    "                               0.35 * materials[\"PerformanceCompatibility\"] +\n",
    "                               0.2 * materials[\"Popularity\"]/100)\n",
    "    # Exclude materials already viewed\n",
    "    # viewed = engagements[engagements[\"StudentID\"] == student_id][\"MaterialID\"].unique()\n",
    "    # recommendations = materials[~materials[\"MaterialID\"].isin(viewed)]\n",
    "    # Get top N recommendations\n",
    "    top_recommendations = materials.sort_values(by=\"TotalScore\", ascending=False).head(top_n)\n",
    "    return top_recommendations[[\"MaterialID\", \"Subject\", \"Difficulty\", \"TotalScore\"]]\\\n",
    "\n",
    "#### IMPOTANT ####\n",
    "####################################################################################################################\n",
    "\"\"\"i have included the viewed materials in the recommendations for the sake of the evaluation of the algorithm othrwise the map@k and ndcg@k will be 0\n",
    "but we can exclude the viewed materials by uncommenting the two lines above for real recommendation as students will not be recommended the materials \n",
    "they have already viewed(i means completed as just viewed and not completed can be recommended but not implemented here) \"\"\"\n",
    "####################################################################################################################   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Recommendations for Each Student\n",
    "In this step, we iterate through each student in the dataset and generate personalized recommendations for them:\n",
    "\n",
    "Generate recommendations for each student: For every student in the dataset, the recommend_materials function is called to calculate the top materials based on their interests, performance, and the material's popularity.\n",
    "\n",
    "Store recommendations: We store the recommendations for each student in a dictionary called student_recommendations, where the key is the student's ID, and the value is a DataFrame of the top recommended materials.\n",
    "\n",
    "Example output: To demonstrate, we print out the top recommendations for a specific student, in this case, student with ID \"S002\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations for Student S002:\n",
      "   MaterialID        Subject Difficulty  TotalScore\n",
      "19       M020  Cybersecurity       Hard    0.788308\n",
      "13       M014             AI       Hard    0.782308\n",
      "8        M009  Cybersecurity       Hard    0.766308\n",
      "31       M032  Cybersecurity       Hard    0.764308\n",
      "24       M025     Blockchain       Hard    0.734308\n"
     ]
    }
   ],
   "source": [
    "# 6. Generate Recommendations for Each Student\n",
    "student_recommendations = {}\n",
    "for student_id in students[\"StudentID\"]:\n",
    "    recs = recommend_materials(student_id)\n",
    "    student_recommendations[student_id] = recs\n",
    "\n",
    "# Example: Print recommendations for a specific student\n",
    "student_id = \"S002\"\n",
    "print(f\"Top recommendations for Student {student_id}:\")\n",
    "print(student_recommendations[student_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Algorithm\n",
    "### 1) Calculate MAP@K for the Recommendation System\n",
    "we implement a function to compute the Mean Average Precision at K (MAP@K) score, an important metric for evaluating recommendation systems:\n",
    "\n",
    "Function Overview: The calculate_map_at_k function calculates the MAP@K score based on:\n",
    "\n",
    "Parameters:\n",
    "recommendations: A dictionary with student IDs as keys and their recommended MaterialIDs as values.\n",
    "engagements: A DataFrame containing data about materials each student has engaged with.\n",
    "k: The number of top recommendations to consider.\n",
    "Average Precision Calculation: For each student:\n",
    "\n",
    "Extract the top K recommendations.\n",
    "Identify relevant materials based on student engagement.\n",
    "Calculate Precision at K by counting hits and averaging the precision scores.\n",
    "MAP@K Score Calculation: The MAP@K score is derived by averaging the precision scores across all students, providing a measure of the recommendation system's accuracy.\n",
    "\n",
    "Example Execution: The code includes an example that computes and prints the MAP@K scores for K values ranging from 0 to 9.\n",
    "\n",
    "This evaluation helps assess how effectively the recommendation system identifies materials that students are likely to engage with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@1: 1.0000\n",
      "MAP@2: 0.8750\n",
      "MAP@3: 0.6865\n",
      "MAP@4: 0.5643\n",
      "MAP@5: 0.5052\n"
     ]
    }
   ],
   "source": [
    "def calculate_map_at_k(recommendations, engagements, k):\n",
    "    \"\"\"\n",
    "    Calculate MAP@K for the recommendation system.\n",
    "\n",
    "    Parameters:\n",
    "        recommendations: Dictionary where keys are student IDs and values are lists of recommended MaterialIDs.\n",
    "        engagements: DataFrame with student engagement data containing 'StudentID' and 'MaterialID'.\n",
    "        k: Number of top recommendations to consider.\n",
    "\n",
    "    Returns:\n",
    "        MAP@K score.\n",
    "    \"\"\"\n",
    "    average_precision_scores = []\n",
    "\n",
    "    for student_id, recommended in recommendations.items():\n",
    "        # Get top K recommendations\n",
    "        top_k_recommended = recommended.head(k)['MaterialID'].tolist()\n",
    "        \n",
    "        # Get relevant items (engaged materials)\n",
    "        relevant_items = engagements[engagements[\"StudentID\"] == student_id][\"MaterialID\"].tolist()\n",
    "\n",
    "        # Calculate Precision at K\n",
    "        hits = 0\n",
    "        precision_at_k = 0\n",
    "\n",
    "        for i, item in enumerate(top_k_recommended):\n",
    "            if item in relevant_items:\n",
    "                hits += 1\n",
    "                precision_at_k += hits / (i + 1)  # Precision = hits / (position + 1)\n",
    "\n",
    "        if hits > 0:\n",
    "            average_precision = precision_at_k / min(hits, k)  # Average precision\n",
    "            average_precision_scores.append(average_precision)\n",
    "\n",
    "    # MAP@K\n",
    "    map_at_k = sum(average_precision_scores) / len(average_precision_scores) if average_precision_scores else 0\n",
    "    return map_at_k\n",
    "\n",
    "# Example usage\n",
    "for i in range(1,6):\n",
    "    k = i # Set K for MAP@K\n",
    "    map_at_k_score = calculate_map_at_k(student_recommendations, engagements, k)\n",
    "    print(f\"MAP@{k}: {map_at_k_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDCG@K for the Recommendation System\n",
    "This section implements a function to compute the Normalized Discounted Cumulative Gain at K (NDCG@K), which evaluates the effectiveness of our recommendations:\n",
    "\n",
    "Function Purpose: The calculate_ndcg_at_k function calculates NDCG@K using:\n",
    "\n",
    "recommendations: Dictionary of student IDs and their recommended materials.\n",
    "engagements: DataFrame of student engagement data.\n",
    "k: Number of top recommendations to consider.\n",
    "DCG Calculation: For each student, the function:\n",
    "\n",
    "Retrieves the top K recommendations.\n",
    "Identifies relevant materials based on engagement.\n",
    "Computes DCG by summing relevance scores, applying position-based discounts.\n",
    "NDCG Calculation: NDCG is derived by normalizing DCG with Ideal DCG (IDCG), providing a score between 0 and 1.\n",
    "\n",
    "Example Execution: The code snippet computes NDCG@K scores for K values from 1 to 10, offering insights into the ranking quality of the recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@1: 0.2100\n",
      "NDCG@2: 0.1674\n",
      "NDCG@3: 0.1727\n",
      "NDCG@4: 0.1824\n",
      "NDCG@5: 0.1834\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_ndcg_at_k(recommendations, engagements, k):\n",
    "    \"\"\"\n",
    "    Calculate NDCG@K for the recommendation system.\n",
    "\n",
    "    Parameters:\n",
    "        recommendations: Dictionary where keys are student IDs and values are DataFrames of recommended MaterialIDs.\n",
    "        engagements: DataFrame with student engagement data containing 'StudentID' and 'MaterialID'.\n",
    "        k: Number of top recommendations to consider.\n",
    "\n",
    "    Returns:\n",
    "        NDCG@K score.\n",
    "    \"\"\"\n",
    "    ndcg_scores = []\n",
    "\n",
    "    for student_id, recommended in recommendations.items():\n",
    "        # Get top K recommendations\n",
    "        top_k_recommended = recommended.head(k)['MaterialID'].tolist()\n",
    "        \n",
    "        # Get relevant items (engaged materials)\n",
    "        relevant_items = engagements[engagements[\"StudentID\"] == student_id][\"MaterialID\"].tolist()\n",
    "\n",
    "        # Calculate DCG\n",
    "        dcg = 0.0\n",
    "        for i, item in enumerate(top_k_recommended):\n",
    "            if item in relevant_items:\n",
    "                # Assign relevance score (can be 1 for engaged materials)\n",
    "                relevance_score = 1\n",
    "                # Use the position in the list for discounting\n",
    "                dcg += relevance_score / np.log2(i + 2)  # i + 2 to avoid log(1) for the first position\n",
    "\n",
    "        # Calculate IDCG (Ideal DCG)\n",
    "        ideal_relevance_scores = [1] * min(len(relevant_items), k)  # All relevant items have a relevance score of 1\n",
    "        idcg = sum(relevance / np.log2(i + 2) for i, relevance in enumerate(ideal_relevance_scores))\n",
    "\n",
    "        # Calculate NDCG\n",
    "        ndcg = dcg / idcg if idcg > 0 else 0\n",
    "        ndcg_scores.append(ndcg)\n",
    "\n",
    "    # Average NDCG@K\n",
    "    ndcg_at_k = sum(ndcg_scores) / len(ndcg_scores) if ndcg_scores else 0\n",
    "    return ndcg_at_k\n",
    "\n",
    "# Example usage\n",
    "for i in range(1,6):\n",
    "    k = i  # Set K for NDCG@K\n",
    "    ndcg_at_k_score = calculate_ndcg_at_k(student_recommendations, engagements, k)\n",
    "    print(f\"NDCG@{k}: {ndcg_at_k_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
